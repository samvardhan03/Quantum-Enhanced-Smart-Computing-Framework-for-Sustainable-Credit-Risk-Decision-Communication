{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî¨ Quantum-Enhanced Credit Risk Prediction\n",
                "\n",
                "**Framework**: Quantum-Enhanced Smart Computing Framework for Sustainable Credit Risk Decision Communication  \n",
                "**Reference**: Jain, Singh, et al. (2026)  \n",
                "\n",
                "This notebook provides a comprehensive, interactive walkthrough of the hybrid quantum-classical credit risk prediction pipeline.\n",
                "\n",
                "---\n",
                "\n",
                "## Table of Contents\n",
                "1. [Setup & Imports](#1-setup--imports)\n",
                "2. [Data Loading & Exploration](#2-data-loading--exploration)\n",
                "3. [Preprocessing Pipeline (Eq. 1‚Äì3)](#3-preprocessing-pipeline)\n",
                "4. [Spectral Feature Engineering (Eq. 5‚Äì6)](#4-spectral-feature-engineering)\n",
                "5. [Quantum Circuit Visualisation (Eq. 4, 7)](#5-quantum-circuit-visualisation)\n",
                "6. [Quantum Kernel & QSVM (Eq. 8)](#6-quantum-kernel--qsvm)\n",
                "7. [Classical Baselines](#7-classical-baselines)\n",
                "8. [Results & Comparison](#8-results--comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path\n",
                "PROJECT_ROOT = Path().resolve().parent\n",
                "if str(PROJECT_ROOT) not in sys.path:\n",
                "    sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from src.preprocessing import (\n",
                "    generate_synthetic_credit_data,\n",
                "    mean_imputation,\n",
                "    min_max_normalize,\n",
                "    one_hot_encode,\n",
                "    preprocess_pipeline,\n",
                ")\n",
                "from src.fft_dct_features import apply_fft, apply_dct, extract_spectral_features\n",
                "from src.quantum_kernel import QuantumKernel, angle_embedding, variational_circuit\n",
                "from src.svm_classifier import QuantumSVM\n",
                "from src.classical_baselines import evaluate_all_baselines\n",
                "from src.evaluation import compute_metrics, plot_confusion_matrix, plot_roc_curve, plot_model_comparison\n",
                "\n",
                "sns.set_theme(style='whitegrid', palette='deep')\n",
                "%matplotlib inline\n",
                "\n",
                "print('All imports successful ‚úì')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate synthetic credit risk data (or load your own CSV)\n",
                "df_raw = generate_synthetic_credit_data(n_samples=2000, random_state=42)\n",
                "print(f'Dataset shape: {df_raw.shape}')\n",
                "df_raw.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "df_raw['loan_status'].value_counts().plot.bar(ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
                "axes[0].set_title('Loan Status Distribution')\n",
                "axes[0].set_xticklabels(['Low Risk (0)', 'High Risk (1)'], rotation=0)\n",
                "\n",
                "df_raw.select_dtypes(include=[np.number]).hist(ax=axes[1] if False else None, figsize=(14, 8), bins=30, edgecolor='white')\n",
                "plt.suptitle('Numerical Feature Distributions', y=1.02, fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Missing values\n",
                "missing = df_raw.isnull().sum()\n",
                "print('Missing values per column:')\n",
                "print(missing[missing > 0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing Pipeline\n",
                "\n",
                "Implementing Eq. 1 (Mean Imputation), Eq. 2 (Min-Max Normalisation), and Eq. 3 (One-Hot Encoding)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step-by-step preprocessing\n",
                "df_imputed = mean_imputation(df_raw)\n",
                "print(f'After imputation ‚Äî missing values: {df_imputed.isnull().sum().sum()}')\n",
                "\n",
                "df_encoded = one_hot_encode(df_imputed)\n",
                "print(f'After one-hot encoding ‚Äî columns: {df_encoded.shape[1]}')\n",
                "\n",
                "target = df_encoded['loan_status']\n",
                "features_df = df_encoded.drop(columns=['loan_status'])\n",
                "features_df = min_max_normalize(features_df)\n",
                "print(f'After normalisation ‚Äî range: [{features_df.min().min():.4f}, {features_df.max().max():.4f}]')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Or use the full pipeline in one call\n",
                "X_train, X_test, y_train, y_test, feature_names = preprocess_pipeline(random_state=42)\n",
                "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Spectral Feature Engineering\n",
                "\n",
                "**Eq. 5**: FFT Power Spectrum ‚Äî captures frequency-domain energy distribution  \n",
                "**Eq. 6**: DCT-II Energy Compaction ‚Äî concentrates signal energy in few coefficients"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstrate FFT on a synthetic signal\n",
                "t = np.linspace(0, 1, 256, endpoint=False)\n",
                "signal = np.sin(2 * np.pi * 5 * t) + 0.5 * np.sin(2 * np.pi * 20 * t)\n",
                "\n",
                "power_spectrum = apply_fft(signal)\n",
                "dct_coeffs = apply_dct(signal, n_components=20)\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "axes[0].plot(t, signal, color='#3498db')\n",
                "axes[0].set_title('Input Signal')\n",
                "axes[0].set_xlabel('Time')\n",
                "\n",
                "axes[1].stem(power_spectrum[:50], linefmt='#e74c3c', markerfmt='ro', basefmt='gray')\n",
                "axes[1].set_title('FFT Power Spectrum (Eq. 5)')\n",
                "axes[1].set_xlabel('Frequency Index')\n",
                "\n",
                "axes[2].bar(range(len(dct_coeffs)), np.abs(dct_coeffs), color='#2ecc71')\n",
                "axes[2].set_title('DCT Coefficients (Eq. 6)')\n",
                "axes[2].set_xlabel('Component Index')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply spectral features to the credit data\n",
                "df_train = pd.DataFrame(X_train, columns=feature_names)\n",
                "spectral_cols = feature_names[:3]  # first 3 numeric features\n",
                "df_spectral = extract_spectral_features(df_train, columns=spectral_cols, n_dct_components=3)\n",
                "\n",
                "new_cols = [c for c in df_spectral.columns if c not in feature_names]\n",
                "print(f'New spectral features ({len(new_cols)}): {new_cols}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Quantum Circuit Visualisation\n",
                "\n",
                "**Eq. 4**: Angle Embedding ‚Äî maps features to qubit rotations  \n",
                "**Eq. 7**: Variational Circuit ‚Äî R_X/R_Z rotations + CNOT entanglers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pennylane as qml\n",
                "\n",
                "N_QUBITS_VIZ = 4\n",
                "N_LAYERS_VIZ = 1\n",
                "\n",
                "dev = qml.device('default.qubit', wires=N_QUBITS_VIZ)\n",
                "wires = list(range(N_QUBITS_VIZ))\n",
                "\n",
                "@qml.qnode(dev)\n",
                "def demo_circuit(x, params):\n",
                "    angle_embedding(x, wires)\n",
                "    variational_circuit(params, wires, n_layers=N_LAYERS_VIZ)\n",
                "    return qml.probs(wires=wires)\n",
                "\n",
                "x_demo = np.array([0.2, 0.5, 0.8, 0.3])\n",
                "params_demo = np.random.default_rng(42).uniform(0, 2*np.pi, (N_LAYERS_VIZ, N_QUBITS_VIZ, 2))\n",
                "\n",
                "# Draw the circuit\n",
                "fig, ax = qml.draw_mpl(demo_circuit)(x_demo, params_demo)\n",
                "plt.title('Quantum Feature Map Circuit (Eq. 4 + Eq. 7)', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Quantum Kernel & QSVM\n",
                "\n",
                "**Eq. 8**: $K(x_i, x_j) = |\\langle\\phi(x_i)|\\phi(x_j)\\rangle|^2$\n",
                "\n",
                "We use subset sampling for tractable quantum simulation on local hardware."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subset for quantum tractability\n",
                "SAMPLE_SIZE = 50\n",
                "N_Q = 4\n",
                "\n",
                "rng = np.random.default_rng(42)\n",
                "idx_train = rng.choice(len(X_train), SAMPLE_SIZE, replace=False)\n",
                "idx_test = rng.choice(len(X_test), SAMPLE_SIZE // 4, replace=False)\n",
                "\n",
                "X_train_q = X_train[idx_train, :N_Q]\n",
                "y_train_q = y_train[idx_train]\n",
                "X_test_q = X_test[idx_test, :N_Q]\n",
                "y_test_q = y_test[idx_test]\n",
                "\n",
                "print(f'Quantum subset: train={len(X_train_q)}, test={len(X_test_q)}, features={N_Q}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute quantum kernel matrix\n",
                "qk = QuantumKernel(n_qubits=N_Q, n_layers=1, random_state=42)\n",
                "K_train = qk.compute_kernel_matrix(X_train_q, verbose=True)\n",
                "\n",
                "# Visualise kernel matrix\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "sns.heatmap(K_train, cmap='viridis', ax=ax, vmin=0, vmax=1)\n",
                "ax.set_title(f'Quantum Kernel Matrix ({SAMPLE_SIZE}√ó{SAMPLE_SIZE})', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Quantum SVM\n",
                "qsvm = QuantumSVM(kernel_fn=qk, n_qubits=N_Q, n_layers=1)\n",
                "qsvm.fit(X_train_q, y_train_q, verbose=True)\n",
                "\n",
                "qsvm_preds = qsvm.predict(X_test_q)\n",
                "qsvm_metrics = compute_metrics(y_test_q, qsvm_preds)\n",
                "print(f'\\nQSVM Accuracy: {qsvm_metrics[\"accuracy\"]:.4f}')\n",
                "print(f'QSVM F1-Score: {qsvm_metrics[\"f1\"]:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Classical Baselines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_results = evaluate_all_baselines(\n",
                "    X_train, X_test, y_train, y_test,\n",
                "    cnn_epochs=30,\n",
                "    verbose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Results & Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_metrics = {}\n",
                "all_metrics['Quantum SVM'] = qsvm_metrics\n",
                "\n",
                "for name, res in baseline_results.items():\n",
                "    m = compute_metrics(y_test, res['predictions'], res['probabilities'])\n",
                "    all_metrics[name] = m\n",
                "\n",
                "# Display as table\n",
                "results_df = pd.DataFrame(all_metrics).T\n",
                "results_df = results_df.sort_values('accuracy', ascending=False)\n",
                "results_df.style.format('{:.4f}').background_gradient(cmap='Greens', axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model comparison bar chart\n",
                "plot_model_comparison(all_metrics)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrices for all models\n",
                "fig, axes = plt.subplots(1, len(baseline_results) + 1, figsize=(5 * (len(baseline_results) + 1), 4))\n",
                "\n",
                "from sklearn.metrics import confusion_matrix as cm_fn\n",
                "\n",
                "# QSVM\n",
                "cm = cm_fn(y_test_q, qsvm_preds)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
                "axes[0].set_title('Quantum SVM')\n",
                "\n",
                "# Baselines\n",
                "for idx, (name, res) in enumerate(baseline_results.items(), start=1):\n",
                "    cm = cm_fn(y_test, res['predictions'])\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
                "    axes[idx].set_title(name)\n",
                "\n",
                "plt.suptitle('Confusion Matrices ‚Äî All Models', fontsize=14, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "**Summary**: This notebook demonstrated the complete hybrid quantum-classical credit risk prediction pipeline,\n",
                "from data preprocessing through spectral feature engineering to quantum kernel computation and model comparison.\n",
                "\n",
                "The Quantum SVM leverages an exponentially large Hilbert space (2‚Åø dimensions) to capture feature correlations\n",
                "intractable for classical kernels, achieving competitive performance on credit risk classification."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}